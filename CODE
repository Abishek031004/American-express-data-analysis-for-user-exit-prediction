import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Load dataset
data_set = pd.read_csv("/Book2.csv")

# Features and Labels
X = data_set.iloc[:, :-1].values
Y = data_set.iloc[:, -1].values

# Encoding categorical features

# 1. Label encoding for Gender column (assumed to be at index 2)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X[:, 2] = le.fit_transform(X[:, 2])

# 2. One-hot encoding for Geography column (assumed to be at index 1)
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

ct = ColumnTransformer(
    transformers=[('encoder', OneHotEncoder(), [1])],
    remainder='passthrough'
)
X = np.array(ct.fit_transform(X))

# Feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

# Splitting into train and test sets
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Building the ANN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer
    Dense(32, activation='relu'),                                   # Second hidden layer
    Dense(1, activation='sigmoid')                                  # Output layer
])

# Compile the ANN
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# Train the ANN
history = model.fit(X_train, Y_train, batch_size=32, epochs=55, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, Y_test)
print(f"\nTest Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

# Single prediction (example input - must match feature count & format)
sample = sc.transform([[1.0, 0.0, 0.0, 447, 1, 31, 7, 0.0, 4, 1, 519360]])
single_pred = model.predict(sample)
print(f"Single Prediction (Exit?): {single_pred[0][0] > 0.5}")

# Batch predictions
Y_pred = model.predict(X_test)
Y_pred = (Y_pred > 0.5).astype(int)  # Convert probabilities to binary (0 or 1)

# Combine predictions with actual values
print(np.concatenate((Y_pred, Y_test.reshape(-1, 1)), axis=1))

# Confusion matrix and accuracy score
from sklearn.metrics import confusion_matrix, accuracy_score

cm = confusion_matrix(Y_test, Y_pred)
print("\nConfusion Matrix:\n", cm)

final_accuracy = accuracy_score(Y_test, Y_pred)
print(f"Final Accuracy: {final_accuracy:.4f}") 
